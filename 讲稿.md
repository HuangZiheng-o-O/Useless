 

We aim to generate realistic human motions that can be guided by spatial constraints, enabling the generated human motion to achieve specific goals, such as following a global trajectory, reaching certain locations, or avoiding obstacles. Although diffusion-based models have significantly improved text-to-motion modeling [8, 54], generating motions that achieve specific goals is still beyond the reach of the current models. Our work addresses this limitation and advances the state-of-the-art in human motion modeling.

We are interested in modeling a full-body human motion that satisfies **a certain scalar goal function** $$G_x(\cdot)$$ **that takes a motion representation** $$x$$ **and measures how far the motion** $$x$$ **is from the goal (lower is better)**. More specifically, $$x \in \mathbb{R}^{N \times M}$$ represents a sequence of human poses for $$M$$ motion steps, where $$N$$ is the dimension of human pose representations, e.g., $$N = 263$$ in the HumanML3D [15] dataset. **Let** $$X$$ **be the random variable associated with** $$x$$. Our goal is to model the following conditional probability using a motion **DPM**:

$$
p(x|G_x(X) = 0)
$$

This can be extended to $$p(x|G_x(X) = 0, d)$$, where $$d$$ is any additional signal, such as text prompts. From now on, we omit $$d$$ to reduce clutter.




Many challenging tasks in motion modeling can be encapsulated within a goal function $$G_z$$ that only depends on the trajectory $$z$$ of the human motion, not the whole motion $$x$$. Let us define $$z \in \mathbb{R}^{L \times M}$$ to be the trajectory part of $$x$$ with length $$M$$ and $$L = 2$$ describing the ground location of the pelvis of a human body. A particular location $$z^{(i)}$$ at motion step $$i$$ describes the pelvis location of the human body on the ground plane. We define a projection $$P^z_x$$ that resizes $$x$$ to match $$z$$ by taking only the $$z$$ part, and its reverse $$P^x_z$$ that resizes $$z$$ to match $$x$$ by filling in zeros. With this, our conditional probability becomes $$p(x|G_z(P^z_x X) = 0)$$.

In this work, we will show how text-to-motion DPMs can be extended to solve several challenging tasks, including trajectory-conditioned motion generation, location-conditioned trajectory planning, and obstacle avoidance trajectory planning. Using our proposed **Emphasis projection** and **dense signal propagation**, we alleviate the sparse guidance problem and enable motion generation based on spatial conditions. The overview of our methods is shown in Fig. 3.

#### 4.1. Emphasis projection

One of the most straightforward approaches for minimizing the goal function $$G_z(\cdot)$$ is by analyzing what trajectories that minimize $$z^* = \arg \min_z G_z(z)$$ look like. For a trajectory conditioning task, a whole trajectory $$z^*$$ is directly given. Our task is to generate the rest of the motion $$x$$. With such knowledge, we can employ **imputation & inpainting** techniques by supplying the motion DPM with the $$x$$-shaped $$P^x_z z^*$$ to guide the generation process.

**Problem 1: Motion incoherence**

Since the imputing trajectory $$z^*$$ is only a small part of the whole motion $$x$$ $$L \ll N$$, we often observe that the DPM ignores the change from imputation and fails to make appropriate changes on the rest of $$x$$. This results in an incoherent local motion that is not aligned or well-coordinated with the imputing trajectory.

**Solution 1: Emphasis projection**

We tackle this problem by giving more emphasis on the trajectory part of motion $$x$$. More specifically, we propose an **Emphasis projection** method that increases the trajectory's...





relative importance within motion $$x$$. We achieve this by utilizing a random matrix $$A = A'B$$, where $$A' \in \mathbb{R}^{N \times N}$$ is a matrix with elements **randomly sampled from** $$\mathcal{N}(0, 1)$$ and $$B \in \mathbb{R}^{N \times N}$$ is a diagonal matrix whose trajectory-related diagonal indexes are $$c$$ and the rest are $$1$$ for emphasizing those trajectory elements. In our case, we emphasize the **rotation and ground location of the pelvis** $$\text{rot}, x, z)$$, in $$x$$ by $$c$$ times. We now have a projected motion $$x^{\text{proj}} = \frac{1}{N - 3 + 3c^2} Ax$$. Note that the fractional term is to maintain the unit variance on $$x^{\text{proj}}$$. The noising process of the projected motion becomes

$$
q(x_t^{\text{proj}}|x_0^{\text{proj}}) = \mathcal{N}(\sqrt{\alpha_t}x_0^{\text{proj}}, (1 - \alpha_t)I).
$$

There is no change on how a DPM that works on the projected motion $$p_\theta(x_{t-1}^{\text{proj}}|x_t^{\text{proj}})$$ operates and treats $$x_t^{\text{proj}}$$.

In Section 6.3, we show that **emphasis projection** is an effective way of solving the motion incoherence problem, and is shown to be substantially better than a straightforward approach of retraining a DPM with an increased loss weight on the trajectory.

**Imputation on the projected motion** $$x^{\text{proj}}$$. We have discussed imputing on the sample $$x_{t-1}$$ in Eq. 3. Here, we introduce an imputation on $$x_0$$ which **modifies the DPMâ€™s belief on the final outcome** $$x_{0, \theta}$$ **by imputing it with** $$z$$. We have found this technique useful in many tasks we are interested in.

Let us define the imputation region of $$z$$ on $$x$$ as $$M_z^x$$. We obtain the imputed $$\tilde{x}_0$$ from

$$
\tilde{x}_0 = (1 - M_z^x) \odot x_{0, \theta} + M_z^x \odot P_z^x Z^* \quad \text{x shaped}
$$

Now operating on the projected motion $$x^{\text{proj}}$$, before we can do imputation, we need to unproject it back to the original motion using $$x_0 = A^{-1}x_0^{\text{proj}}$$, and then project the imputed $$\tilde{x}_0$$ back using $$\tilde{x}_0^{\text{proj}} = A\tilde{x}_0$$. We obtain the imputed...




motion under emphasis projection $$\tilde{x}_0^{\text{proj}}$$ from

$$
\tilde{x}_0^{\text{proj}} = A \left( (1 - M_z^x) \odot \left( A^{-1} x_0^{\text{proj}} \right) + M_z^x \odot P_z^x z^* \right)
$$

Substituting $$\tilde{x}_0^{\text{proj}}$$ into Eq. 1, we obtain the new mean $$\tilde{\mu}_t^{\text{proj}}$$ for sampling $$x_{t-1}^{\text{proj}} \sim \mathcal{N}(\tilde{\mu}_t^{\text{proj}}, \Sigma_t)$$.

#### 4.2. Dense guidance signal with a learned denoiser

Another way to minimize the goal function $$G_z(\cdot)$$ is by adjusting the sample of **each diffusion step** $$x_{t-1}$$ toward a region with **lower** $$G_z$$. This trick is called **classifier guidance** [13]. The direction of change corresponds to a score function $$\nabla_{x_t} \log p(G_x(X_t) = 0|x_t)$$ which can be approximated as a direction $$\Delta_{x_0} = - \nabla_{x_0} G_z(P_z^x x_{0, \theta})$$ that reduces the goal function. We can guide the generative process by nudging the DPM's prediction as $$x_0 = x_{0, \theta} + \Delta_{x_0}$$. While imputation requires the minimizer $$z^*$$ of $$G_z$$, which might not be easy to obtain or may not be unique, this trick only requires the easier-to-obtain direction of change.

**Applying classifier guidance together with imputation.** Whenever available, we want to utilize signals from both imputation and classifier guidance techniques to help guide the generative process. Imputation is explicit but may encounter sparsity in time, while classifier guidance is indirect but dense. We want to use the direct signal from imputation wherever available (with mask $$M_z^x$$, and the rest from classifier guidance (with mask $$1 - M_z^x$$. Based on Eq. 2, imputation-aware classifier guidance can be written as

$$
\mu_t = \tilde{\mu}_t - (1 - M_z^x) \odot s \Sigma_t \nabla_{x_t} G_z(P_z^x f(x_t))
$$

where $$\tilde{\mu}$$ is an imputed sampling mean. By replacing $$\tilde{\mu}$$ with $$\tilde{\mu}^{\text{proj}}$$, we get classifier guidance together with imputation that works with emphasis projection as

$$
\Delta_\mu = -s \Sigma_t A^{-1} \nabla_{x_t} G_z(P_z^x A^{-1} f(x_t^{\text{proj}}))
$$

$$
\mu_t^{\text{proj}} = \tilde{\mu}_t^{\text{proj}} + A(1 - M_z^x) \odot \Delta_\mu
$$

---




#### 5.2. Keyframe-conditioned generation

The locations of ground positions at specific times can be used to define locations that we wish the generated motion to reach. This task is a generalized version of the trajectory-conditioned generation where only a partial and potentially sparse trajectory is given. Let $$\mathbf{y} \in \mathbb{R}^{2 \times M}$$ be a trajectory describing keyframe locations and a mask $$M_y^z$$ describe the key motion steps. Our goal function of a motion $$x$$ is

$$
G_x(x) := \sum_i \left\| M_y^z (P_x^z x - \mathbf{y}) \right\|_p \quad (12)
$$

Consequently, $$G_z(z) = \sum_i \left\| M_y^z (z - \mathbf{y}) \right\|_p$$. Due to the partial trajectory $$\mathbf{y}$$, the imputation region of $$\mathbf{y}$$ on $$x$$ becomes $$M_y^x = P_x^z M_y^z$$.

**Two-stage guided motion generation.** Generating both the trajectory and motion simultaneously under a conditioning signal can be challenging and may result in lower quality motion. To address this issue, we propose a two-step approach. First, we generate a trajectory $$z$$ that satisfies the keyframe locations and then generate the motion $$x$$ given the trajectory (following Section 5.1). Our overall pipeline is depicted in Figure 2 (a). We offer two options for generating the trajectory from keyframe locations $$\mathbf{y}$$: a point-to-point trajectory and a trajectory DPM.

The **point-to-point trajectory** connects consecutive keyframe locations with a straight line. These unrealistic trajectories can be used as imputation signals for the motion DPM during the early phase $$t \geq \tau)$$. If $$\tau$$ is large enough, the DPM will adjust the given trajectory to a higher quality one. However, if $$\tau$$ is too large, the DPM may generate a motion that does not perform well on $$G_z$$.

The **trajectory DPM** $$p_{\phi}(z_{t-1}|z_t)$$, which is trained using the same dataset but with a smaller network, can be used to generate the trajectory under the guidance signal from $$G_z$$. We summarize our two-stage approach in Algorithm 1.

It is also possible to combine the two methods, as the point-to-point trajectory can serve as a useful guidance signal for the trajectory DPM during $$t \geq \tau$$. After that, the trajectory DPM is subject to the usual imputation and classifier guidance from $$G_z$$. By tuning $$\tau$$, we can balance between trajectory diversity and lower scores on $$G_z$$.